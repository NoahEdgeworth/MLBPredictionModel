{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDfg</th>\n",
       "      <th>Season</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Age</th>\n",
       "      <th>G</th>\n",
       "      <th>AB</th>\n",
       "      <th>PA</th>\n",
       "      <th>H</th>\n",
       "      <th>1B</th>\n",
       "      <th>...</th>\n",
       "      <th>PA_change</th>\n",
       "      <th>AVG_career_avg</th>\n",
       "      <th>HR_career_avg</th>\n",
       "      <th>RBI_career_avg</th>\n",
       "      <th>OBP_career_avg</th>\n",
       "      <th>PA_career_avg</th>\n",
       "      <th>next_AVG</th>\n",
       "      <th>next_HR</th>\n",
       "      <th>next_RBI</th>\n",
       "      <th>next_OBP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9256</td>\n",
       "      <td>2020</td>\n",
       "      <td>A.J. Pollock</td>\n",
       "      <td>LAD</td>\n",
       "      <td>32</td>\n",
       "      <td>55</td>\n",
       "      <td>196</td>\n",
       "      <td>210</td>\n",
       "      <td>54</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.276</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.314000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>0.245</td>\n",
       "      <td>14.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15640</td>\n",
       "      <td>2021</td>\n",
       "      <td>Aaron Judge</td>\n",
       "      <td>NYY</td>\n",
       "      <td>29</td>\n",
       "      <td>148</td>\n",
       "      <td>550</td>\n",
       "      <td>633</td>\n",
       "      <td>158</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.287</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.373000</td>\n",
       "      <td>633.000000</td>\n",
       "      <td>0.311</td>\n",
       "      <td>62.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10950</td>\n",
       "      <td>2020</td>\n",
       "      <td>Adam Duvall</td>\n",
       "      <td>ATL</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "      <td>190</td>\n",
       "      <td>209</td>\n",
       "      <td>45</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.237</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.301000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>0.228</td>\n",
       "      <td>38.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15223</td>\n",
       "      <td>2019</td>\n",
       "      <td>Adam Frazier</td>\n",
       "      <td>PIT</td>\n",
       "      <td>27</td>\n",
       "      <td>152</td>\n",
       "      <td>554</td>\n",
       "      <td>608</td>\n",
       "      <td>154</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.278</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>0.230</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15223</td>\n",
       "      <td>2020</td>\n",
       "      <td>Adam Frazier</td>\n",
       "      <td>PIT</td>\n",
       "      <td>28</td>\n",
       "      <td>58</td>\n",
       "      <td>209</td>\n",
       "      <td>230</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>-378.0</td>\n",
       "      <td>0.254</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.316500</td>\n",
       "      <td>419.000000</td>\n",
       "      <td>0.305</td>\n",
       "      <td>5.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>17232</td>\n",
       "      <td>2020</td>\n",
       "      <td>Yoan Moncada</td>\n",
       "      <td>CHW</td>\n",
       "      <td>25</td>\n",
       "      <td>52</td>\n",
       "      <td>200</td>\n",
       "      <td>231</td>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>-328.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>51.5</td>\n",
       "      <td>0.343500</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>0.263</td>\n",
       "      <td>14.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>19556</td>\n",
       "      <td>2021</td>\n",
       "      <td>Yordan Alvarez</td>\n",
       "      <td>HOU</td>\n",
       "      <td>24</td>\n",
       "      <td>144</td>\n",
       "      <td>537</td>\n",
       "      <td>598</td>\n",
       "      <td>149</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.277</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>0.306</td>\n",
       "      <td>37.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>19198</td>\n",
       "      <td>2019</td>\n",
       "      <td>Yuli Gurriel</td>\n",
       "      <td>HOU</td>\n",
       "      <td>35</td>\n",
       "      <td>144</td>\n",
       "      <td>564</td>\n",
       "      <td>612</td>\n",
       "      <td>168</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.298</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.343000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>19198</td>\n",
       "      <td>2020</td>\n",
       "      <td>Yuli Gurriel</td>\n",
       "      <td>HOU</td>\n",
       "      <td>36</td>\n",
       "      <td>57</td>\n",
       "      <td>211</td>\n",
       "      <td>230</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>-382.0</td>\n",
       "      <td>0.265</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.308500</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>0.319</td>\n",
       "      <td>15.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>19198</td>\n",
       "      <td>2021</td>\n",
       "      <td>Yuli Gurriel</td>\n",
       "      <td>HOU</td>\n",
       "      <td>37</td>\n",
       "      <td>143</td>\n",
       "      <td>530</td>\n",
       "      <td>605</td>\n",
       "      <td>169</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>375.0</td>\n",
       "      <td>0.283</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>482.333333</td>\n",
       "      <td>0.242</td>\n",
       "      <td>8.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows Ã— 345 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IDfg  Season            Name Team  Age    G   AB   PA    H   1B  ...  \\\n",
       "0     9256    2020    A.J. Pollock  LAD   32   55  196  210   54   29  ...   \n",
       "1    15640    2021     Aaron Judge  NYY   29  148  550  633  158   95  ...   \n",
       "2    10950    2020     Adam Duvall  ATL   31   57  190  209   45   21  ...   \n",
       "3    15223    2019    Adam Frazier  PIT   27  152  554  608  154  104  ...   \n",
       "4    15223    2020    Adam Frazier  PIT   28   58  209  230   48   34  ...   \n",
       "..     ...     ...             ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "385  17232    2020    Yoan Moncada  CHW   25   52  200  231   45   28  ...   \n",
       "386  19556    2021  Yordan Alvarez  HOU   24  144  537  598  149   80  ...   \n",
       "387  19198    2019    Yuli Gurriel  HOU   35  144  564  612  168   95  ...   \n",
       "388  19198    2020    Yuli Gurriel  HOU   36   57  211  230   49   30  ...   \n",
       "389  19198    2021    Yuli Gurriel  HOU   37  143  530  605  169  123  ...   \n",
       "\n",
       "     PA_change  AVG_career_avg  HR_career_avg  RBI_career_avg  OBP_career_avg  \\\n",
       "0          NaN           0.276      16.000000            34.0        0.314000   \n",
       "1          NaN           0.287      39.000000            98.0        0.373000   \n",
       "2          NaN           0.237      16.000000            33.0        0.301000   \n",
       "3          NaN           0.278      10.000000            50.0        0.336000   \n",
       "4       -378.0           0.254       8.500000            36.5        0.316500   \n",
       "..         ...             ...            ...             ...             ...   \n",
       "385     -328.0           0.270      15.500000            51.5        0.343500   \n",
       "386        NaN           0.277      33.000000           104.0        0.346000   \n",
       "387        NaN           0.298      31.000000           104.0        0.343000   \n",
       "388     -382.0           0.265      18.500000            63.0        0.308500   \n",
       "389      375.0           0.283      17.333333            69.0        0.333333   \n",
       "\n",
       "     PA_career_avg  next_AVG  next_HR  next_RBI  next_OBP  \n",
       "0       210.000000     0.245     14.0      56.0     0.292  \n",
       "1       633.000000     0.311     62.0     131.0     0.425  \n",
       "2       209.000000     0.228     38.0     113.0     0.281  \n",
       "3       608.000000     0.230      7.0      23.0     0.297  \n",
       "4       419.000000     0.305      5.0      43.0     0.368  \n",
       "..             ...       ...      ...       ...       ...  \n",
       "385     395.000000     0.263     14.0      61.0     0.375  \n",
       "386     598.000000     0.306     37.0      97.0     0.406  \n",
       "387     612.000000     0.232      6.0      22.0     0.274  \n",
       "388     421.000000     0.319     15.0      81.0     0.383  \n",
       "389     482.333333     0.242      8.0      53.0     0.288  \n",
       "\n",
       "[390 rows x 345 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load feature data\n",
    "df = pd.read_csv('../Data/processed/features_and_targets.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our target variables and features\n",
    "targets = ['next_AVG', 'next_HR', 'next_RBI', 'next_OBP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-numeric columns and target variables from features\n",
    "feature_cols = df.select_dtypes(include=[np.number]).columns\n",
    "feature_cols = [col for col in feature_cols if col not in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modeling next_AVG:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m\n\u001b[1;32m     14\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinear Regression\u001b[39m\u001b[38;5;124m'\u001b[39m: LinearRegression(),\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m: RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Make Predictions\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/PycharmProjects/MLBPredictionModel/mlb_venv/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/MLBPredictionModel/mlb_venv/lib/python3.11/site-packages/sklearn/linear_model/_base.py:601\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    597\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[1;32m    599\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 601\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    611\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[0;32m~/PycharmProjects/MLBPredictionModel/mlb_venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/PycharmProjects/MLBPredictionModel/mlb_venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1370\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m     )\n\u001b[1;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[0;32m-> 1370\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1389\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/PycharmProjects/MLBPredictionModel/mlb_venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/MLBPredictionModel/mlb_venv/lib/python3.11/site-packages/sklearn/utils/validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/MLBPredictionModel/mlb_venv/lib/python3.11/site-packages/sklearn/utils/validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     )\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Create seperate models for each target\n",
    "results = {}\n",
    "for target in targets:\n",
    "    print(f'\\nModeling {target}:')\n",
    "    \n",
    "    # Prepare X and Y\n",
    "    X = df[feature_cols]\n",
    "    y = df[target]\n",
    "    \n",
    "    # Split data \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train Models\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    }\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make Predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate Metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        print(f'\\n{name} Results:')\n",
    "        print(f'Mean Squared Error: {mse:.4f}')\n",
    "        print(f'Mean Absolute Error: {mae:.4f}')\n",
    "        print(f'R^2 Score: {r2:.4f}')\n",
    "        \n",
    "        # Store Results\n",
    "        results[(target, name)] = {\n",
    "            'mse': mse,\n",
    "            'mae': mae,\n",
    "            'r2': r2\n",
    "        }\n",
    "        \n",
    "# Save Results\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.to_csv('../Models/model_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modeling next_AVG:\n",
      "\n",
      "Linear Regression Results:\n",
      "Mean Squared Error: 3.1578\n",
      "Mean Absolute Error: 1.1477\n",
      "RÂ² Score: -4095.2505\n",
      "\n",
      "Random Forest Results:\n",
      "Mean Squared Error: 0.0008\n",
      "Mean Absolute Error: 0.0234\n",
      "RÂ² Score: -0.0549\n",
      "\n",
      "Modeling next_HR:\n",
      "\n",
      "Linear Regression Results:\n",
      "Mean Squared Error: 19927395.3746\n",
      "Mean Absolute Error: 1217.2877\n",
      "RÂ² Score: -201856.8940\n",
      "\n",
      "Random Forest Results:\n",
      "Mean Squared Error: 48.7951\n",
      "Mean Absolute Error: 5.3154\n",
      "RÂ² Score: 0.5057\n",
      "\n",
      "Modeling next_RBI:\n",
      "\n",
      "Linear Regression Results:\n",
      "Mean Squared Error: 293808154.5707\n",
      "Mean Absolute Error: 4773.7523\n",
      "RÂ² Score: -504713.3976\n",
      "\n",
      "Random Forest Results:\n",
      "Mean Squared Error: 286.4830\n",
      "Mean Absolute Error: 13.6418\n",
      "RÂ² Score: 0.5079\n",
      "\n",
      "Modeling next_OBP:\n",
      "\n",
      "Linear Regression Results:\n",
      "Mean Squared Error: 8.7118\n",
      "Mean Absolute Error: 2.2586\n",
      "RÂ² Score: -8628.4778\n",
      "\n",
      "Random Forest Results:\n",
      "Mean Squared Error: 0.0009\n",
      "Mean Absolute Error: 0.0224\n",
      "RÂ² Score: 0.1161\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load feature data\n",
    "df = pd.read_csv('../Data/processed/features_and_targets.csv')\n",
    "\n",
    "# Define our target variables and features\n",
    "targets = ['next_AVG', 'next_HR', 'next_RBI', 'next_OBP']\n",
    "\n",
    "# Remove non-numeric columns and target variables from features\n",
    "feature_cols = df.select_dtypes(include=[np.number]).columns\n",
    "feature_cols = [col for col in feature_cols if col not in targets]\n",
    "\n",
    "# Create imputer for missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Create separate models for each target\n",
    "results = {}\n",
    "for target in targets:\n",
    "    print(f\"\\nModeling {target}:\")\n",
    "    \n",
    "    # Prepare X and y\n",
    "    X = df[feature_cols]\n",
    "    y = df[target]\n",
    "    \n",
    "    # Remove rows where target is NaN\n",
    "    mask = ~y.isna()\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    \n",
    "    # Impute missing values in features\n",
    "    X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train models\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    }\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"\\n{name} Results:\")\n",
    "        print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "        print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "        print(f\"RÂ² Score: {r2:.4f}\")\n",
    "        \n",
    "        # Store results\n",
    "        results[(target, name)] = {\n",
    "            'mse': mse,\n",
    "            'mae': mae,\n",
    "            'r2': r2\n",
    "        }\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.to_csv('../Models/model_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 most important features for predicting next_AVG:\n",
      "            feature  importance\n",
      "331  AVG_career_avg    0.050540\n",
      "312             xBA    0.045615\n",
      "307         HardHit    0.019131\n",
      "209            TTO%    0.013953\n",
      "286            BB%+    0.013043\n",
      "203           Pull%    0.010231\n",
      "100        O-Swing%    0.009947\n",
      "285            AVG+    0.008535\n",
      "87              wSL    0.008473\n",
      "25               LD    0.008432\n",
      "\n",
      "Top 10 most important features for predicting next_HR:\n",
      "           feature  importance\n",
      "1           Season    0.189272\n",
      "305        Barrel%    0.182785\n",
      "39             ISO    0.037806\n",
      "290           ISO+    0.027846\n",
      "308       HardHit%    0.020854\n",
      "332  HR_career_avg    0.020126\n",
      "306          maxEV    0.013979\n",
      "44             FB%    0.011375\n",
      "301         Hard%+    0.011114\n",
      "318        prev_HR    0.009504\n",
      "\n",
      "Top 10 most important features for predicting next_RBI:\n",
      "           feature  importance\n",
      "1           Season    0.447447\n",
      "305        Barrel%    0.033712\n",
      "39             ISO    0.032079\n",
      "332  HR_career_avg    0.030231\n",
      "290           ISO+    0.011596\n",
      "313           xSLG    0.011585\n",
      "69          Clutch    0.008929\n",
      "307        HardHit    0.007031\n",
      "106          Zone%    0.006530\n",
      "24              FB    0.005948\n",
      "\n",
      "Top 10 most important features for predicting next_OBP:\n",
      "            feature  importance\n",
      "334  OBP_career_avg    0.134730\n",
      "314           xwOBA    0.019687\n",
      "13               BB    0.013667\n",
      "221        vCH (pi)    0.013629\n",
      "208           Hard%    0.012741\n",
      "33              BB%    0.012601\n",
      "64              REW    0.012090\n",
      "36              OBP    0.011945\n",
      "35             BB/K    0.011391\n",
      "242       XX-X (pi)    0.011226\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../Data/processed/features_and_targets.csv')\n",
    "\n",
    "# Let's look at feature importance for each target\n",
    "targets = ['next_AVG', 'next_HR', 'next_RBI', 'next_OBP']\n",
    "\n",
    "for target in targets:\n",
    "    print(f\"\\nTop 10 most important features for predicting {target}:\")\n",
    "    \n",
    "    # Prepare X and y\n",
    "    feature_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    feature_cols = [col for col in feature_cols if col not in targets]\n",
    "    X = df[feature_cols]\n",
    "    y = df[target]\n",
    "    \n",
    "    # Remove rows where target is NaN\n",
    "    mask = ~y.isna()\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    \n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "    \n",
    "    # Train Random Forest\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    # Get feature importance\n",
    "    importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': rf.feature_importances_\n",
    "    })\n",
    "    \n",
    "    # Show top 10 features\n",
    "    print(importance.sort_values('importance', ascending=False).head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlb_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
